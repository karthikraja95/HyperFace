# -*- coding: utf-8 -*-
"""Neu_Pro_v12_compute.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zA-VUpbaAEaYJaJpyLNbwN4fQYKmAd4A
"""

#from google.colab import drive
#drive.mount('/content/gdrive')

# %cd /content/gdrive/My Drive/face_data/

from __future__ import print_function
import argparse
import math
import numpy as np
import numpy.random as npr
import scipy.misc
import time
import torch 
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable
import matplotlib
import matplotlib.pyplot as plt 
import torchvision
import torchvision.transforms as transforms
import os
import torch.cuda as cutorch
import pdb

file = open("test12.txt", "w+")

def to_var(np_a, gpu=True):
    np_a = np_a.flatten()
    temp = []
    for j in np_a:
        temp.append(j)
    np_a = torch.from_numpy(np.array(temp, dtype = float))
    if gpu:
        return Variable(np_a.cuda())
    else:
        return Variable(np_a)

def compute_loss_1(outputs, labels):
    #criterion = nn.CrossEntropyLoss()
    #criterion = nn.BCELoss()
    #return criterion(outputs.float(), labels.float() )
    #pdb.set_trace()
    #outputs = outputs.float()
    #labels = labels.float()
    small = 1e-8
    l = -(torch.mul(labels,torch.log(outputs+small)) + torch.mul((1-labels), torch.log(1-outputs + small)))
    l=torch.sum(l)/len(labels)
    return l
    
def compute_loss_2(outputs, labels, labels_face):
    #outputs = 227*outputs
    #labels = 227*labels
    #pdb.set_trace()
    #labels_face = torch.max(labels_face, 1)[0].float()
    #pdb.set_trace()
    #labels_face = labels_face.reshape(-1,1)
    mse = torch.sum((outputs.float() - labels.float()), dim = 1)**2
    #mse = torch.mul(mse.reshape(-1,1), labels_face.float())
    #num_non_zero = ((labels_face==0).sum()).float()
    mse = torch.sum(mse)/136
    mse = mse/len(labels_face)
    return mse
    #criterion = nn.MSELoss()
    #return criterion(outputs, labels)

def compute_loss_3(outputs, labels, labels_face):
    #labels_face = torch.max(labels_face, 1)[0].float()
    #pdb.set_trace()
    #labels_face = labels_face.reshape(-1,1)
    mse = torch.sum((outputs.float() - labels.float()), dim = 1)**2
    #mse = torch.mul(mse.reshape(-1,1), labels_face.float())
    #num_non_zero = ((labels_face==0).sum()).float()
    mse = torch.sum(mse)/3
    mse = mse/len(labels_face)
    return mse
    #criterion = nn.MSELoss()
    #return criterion(outputs, labels)
    
def run_validation_step(hf, x_val, y_val_face, y_val_landmarks, y_val_pose, batch_size):
    #correct = 0.0
    val_losses = []
    val_face_losses = []
    val_landmark_losses = []
    val_pose_losses = []
    
    for i, (xs, yfs, yls, yps) in enumerate(get_batch(x_val,
                                            y_val_face,
                                            y_val_landmarks,
                                            y_val_pose,
                                            args.batch_size)):
        images = to_var(xs, args.gpu)
        labels_face = to_var(yfs, args.gpu).float()
        labels_landmarks = to_var(yls, args.gpu).float()
        labels_pose = to_var(yps, args.gpu).float()
        faceoutput, landmarksoutput, poseoutput = hf(images)
        val_face_loss = compute_loss_1(faceoutput, labels_face)
        #print(face_loss)
        val_landmarks_loss = compute_loss_2(landmarksoutput, labels_landmarks, labels_face)
        
        val_pose_loss = compute_loss_3(poseoutput, labels_pose, labels_face)
        val_total_loss = val_face_loss + 5*val_landmarks_loss + 5*val_pose_loss
        #print("######################################")
        
        val_losses.append(val_total_loss.data.item())
        val_face_losses.append(val_face_loss.data.item())
        val_landmark_losses.append(val_landmarks_loss.data.item())
        val_pose_losses.append(val_pose_loss.data.item())
                   
   #print ("Val Face Loss: ", np.mean(val_face_losses))
   #print("Val Landmark Loss: ", np.mean(val_landmark_losses))
   #print("Val Pose Loss: ", np.mean(val_pose_losses))
    file.write("%f ," % np.mean(val_face_losses))
    file.write("%f ," % np.mean(val_landmark_losses))
    file.write("%f ," % np.mean(val_pose_losses))
    file.write("%f ," % np.mean(val_losses))
    cross_val_loss = np.mean(val_losses)
    return cross_val_loss
    
def get_batch(x, y1, y2, y3, batch_size):
    
    N = np.shape(x)[0]
    
    assert N == np.shape(y1)[0]
    assert N == np.shape(y2)[0]
    assert N == np.shape(y3)[0]
    for i in range(0, N, batch_size):
        batch_x = x[i:i+batch_size, :]
        batch_y1 = y1[i:i+batch_size, :]
        batch_y2 = y2[i:i+batch_size, :]
        batch_y3 = y3[i:i+batch_size, :]
        yield (batch_x, batch_y1, batch_y2, batch_y3)

class hyperface(nn.Module):

    def __init__(self):
        
        super(hyperface, self).__init__()
               
        ############### YOUR CODE GOES HERE ###############
        
        
        self.conv1 = nn.Sequential(
            nn.Conv2d(in_channels = 3, out_channels = 96, kernel_size=11, stride=4, padding=0),
            nn.BatchNorm2d(num_features=96),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=3, stride=2), 
            )
        
        self.conv1a = nn.Sequential(
            nn.Conv2d(in_channels = 96, out_channels = 256, kernel_size=4, stride=4),
            nn.BatchNorm2d(num_features=256),
            nn.ReLU(),
            )

        self.conv2 = nn.Sequential(
            nn.Conv2d(in_channels = 96, out_channels = 256, kernel_size=5, stride=1, padding=2),
            nn.BatchNorm2d(num_features=256),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2),)


        self.conv3 = nn.Sequential(
            nn.Conv2d(in_channels = 256, out_channels = 384, kernel_size=3, stride=1, padding=1 ),
            nn.BatchNorm2d(num_features=384),
            nn.ReLU(),
            )

        self.conv3a = nn.Sequential(
            nn.Conv2d(in_channels = 384, out_channels = 256, kernel_size=2, stride=2, padding=0),
            nn.BatchNorm2d(num_features=256),
            nn.ReLU(),
            )


        self.conv4 = nn.Sequential(
            nn.Conv2d(in_channels = 384, out_channels = 384, kernel_size=3, stride=1, padding=1 ),
            nn.BatchNorm2d(num_features=384),
            nn.ReLU(),
            )

        self.conv5 = nn.Sequential(
            nn.Conv2d(in_channels = 384, out_channels = 256, kernel_size=3, stride=1, padding=1 ),
            nn.BatchNorm2d(num_features=256),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=3, stride=2),
            )
        
        
        self.conv_all = nn.Sequential(
            nn.Conv2d(in_channels = 256+256+256, out_channels = 192, kernel_size=1, stride=1, padding=0 ),)
        
        self.fc_full = nn.Sequential(
            nn.Linear(in_features = 6*6*192, out_features = 3072),
            nn.ReLU(),)
        
        self.fc_detection1 = nn.Sequential(
            nn.Linear(in_features = 3072, out_features = 512),
            nn.ReLU(),)
        
        self.fc_detection2 = nn.Sequential(
            nn.Linear(in_features = 512, out_features = 1),
            nn.Softmax(dim=0),
        )
        
        self.fc_landmarks1 = nn.Sequential(
            nn.Linear(in_features = 3072, out_features = 512),
            nn.ReLU(),)
        
        self.fc_landmarks2 = nn.Sequential(
            nn.Linear(in_features = 512, out_features = 136),)
        
        '''
        self.fc_visibility1 = nn.Sequential(
            nn.Linear(in_features = 3072, out_features = 512),
            nn.ReLU(),)
        
        self.fc_visibility2 = nn.Sequential(
            nn.Linear(in_features = 512, out_features = 68),)
        '''
        
        self.fc_pose1 = nn.Sequential(
            nn.Linear(in_features = 3072, out_features = 512),
            nn.ReLU(),)
        
        
        self.fc_pose2 = nn.Sequential(
            nn.Linear(in_features = 512, out_features = 3),
            #nn.Softmax(dim=0)
        )
        
        
    def forward(self, x):
        x=x.view(-1,3,227,227)
        x=x.float()
        #print("x:",x.shape)
        self.out1 = self.conv1(x)
        self.out1a = self.conv1a(self.out1)
        self.out2 = self.conv2(self.out1)
        self.out3 = self.conv3(self.out2)
        self.out3a = self.conv3a(self.out3)
        self.out4 = self.conv4(self.out3)
        self.out5 = self.conv5(self.out4)
        #print("1a:",self.out1a.shape)
        #print("3a:",self.out3a.shape)
        #print("5:",self.out5.shape)
        self.concat = torch.cat((self.out1a, self.out3a, self.out5), dim=1)
        self.out_convall = self.conv_all(self.concat)
        self.flat = torch.flatten(self.out_convall, start_dim=1, end_dim=-1)
        #print("flat:", self.out_convall.shape)
        #print("flat:", self.flat.shape)
        self.out_fc = self.fc_full(self.flat)
        self.out_detection = self.fc_detection1(self.out_fc)
        self.out_faceoutput = self.fc_detection2(self.out_detection)
        self.out_landmarks = self.fc_landmarks1(self.out_fc)
        self.out_landmarksoutput = self.fc_landmarks2(self.out_landmarks)
        self.out_pose = self.fc_pose1(self.out_fc)
        self.out_poseoutput = self.fc_pose2(self.out_pose)
        #self.out_visibility = self.fc_visibility1(flatten)
        #self.out_visibilityoutput = self.fc_visibility2(out_visibility)
        #self.outputs = torch.from_numpy(np.array([self.out_faceoutput, self.out_landmarksoutput, self.out_poseoutput]))
        #pdb.set_trace()
        #face_loss = compute_loss_1(self.out_faceoutput, labels_face)
        #landmarks_loss = compute_loss_2(self.out_landmarksoutput, labels_landmarks,labels_face)
        #pose_loss = compute_loss_3(self.out_poseoutput, labels_pose,labels_face)
        #loss = 5*landmarks_loss + pose_loss + face_loss
        return self.out_faceoutput, self.out_landmarksoutput, self.out_poseoutput

def train(args, hf = None):

    torch.set_num_threads(5)
    npr.seed(args.seed)

    # Save directory
    save_dir = "outputs/" + args.experiment_name
    
    #Loading the model
    if hf is None:
        if args.model == "hyperface":
            hf = hyperface()
    if args.load_path:
        checkpoint = torch.load(args.load_path)
        hf.load_state_dict(checkpoint['state_dict'])
        print("model loaded!")
        
    if args.gpu: 
        hf.cuda()
    #if args.load_path:
    #    optimizer.load_state_dict(checkpoint['optimizer'])        
        
    # LOSS FUNCTION
    D_parameters = [
        {'params':hf.fc_detection1.parameters()},
        {'params':hf.fc_detection2.parameters()},
        {'params':hf.fc_landmarks1.parameters()},
        {'params':hf.fc_landmarks2.parameters()},
        {'params':hf.fc_pose1.parameters()},
        {'params':hf.fc_pose2.parameters()},
        {'params':hf.fc_full.parameters()},
        {'params':hf.conv_all.parameters()},
                  ]
    
    #D_parameters = []
    #for name, param in hf.named_parameters():
    #    #print(name)
    #    if param.requires_grad==True:
    #        D_parameters.append(param)
            
    #optimizer = torch.optim.Adam(D_parameters, lr=args.learn_rate)
    optimizer = torch.optim.SGD(hf.parameters(), lr = args.learn_rate, momentum=0.9)
    

    #Load data

    print("Loading data...")
    #np_data = np.load(args.data, allow_pickle=True)
    np_data = args.data
    #np.random.shuffle(np_data)
    x = np_data[:,0].reshape(-1,1)
    #y_train = np.concatenate((np_data[:,1].reshape(-1,1), np_data[:,2].reshape(-1,1),np_data[:,3].reshape(-1,1)), axis=1)
    y_face = np_data[:,1].reshape(-1,1)
    y_landmarks = np_data[:,2].reshape(-1,1)
    y_pose = np_data[:,3].reshape(-1,1)

    x_train = x[0:900,:]
    #print('xtrain:', np.shape(x)[0])
    y_train_face = y_face[0:900,:]
    y_train_landmarks = y_landmarks[0:900,:]
    y_train_pose = y_pose[0:900,:]
        
    x_val = x[900:,:]
    #print('xval:', np.shape(x_val)[0])
    y_val_face = y_face[900:,:]
    y_val_landmarks = y_landmarks[900:,:]
    y_val_pose = y_pose[900:,:]    
    
    #del np_data, y_face, y_landmarks, y_pose


    # Create the outputs folder if not created already
    if not os.path.exists(save_dir):
        os.makedirs(save_dir)

    print("Beginning training ...")
    
    start = time.time()
    #optimizer.load_state_dict(checkpoint['optimizer'])
    
    
    for epoch in range(args.epochs):
        # Train the Model
        hf.train() 
        losses = []
        face_losses = []
        landmark_losses = []
        pose_losses = []


        for i, data in enumerate(get_batch(x_train,
                                            y_train_face,
                                            y_train_landmarks,
                                            y_train_pose,
                                            args.batch_size)):
            xs, yfs, yls, yps = data
            images = to_var(xs, args.gpu)
            labels_face = to_var(yfs, args.gpu).float()
            labels_landmarks = to_var(yls, args.gpu).float()
            labels_pose = to_var(yps, args.gpu).float()
            faceoutput, landmarksoutput,poseoutput = hf(images)
            #loss  = hf(images, labels_face, labels_landmarks, labels_pose)
            # Forward + Backward + Optimize
            
            face_loss = compute_loss_1(faceoutput, labels_face)
            landmarks_loss = compute_loss_2(landmarksoutput, labels_landmarks,labels_face)
            pose_loss = compute_loss_3(poseoutput, labels_pose, labels_face)
            total_loss = face_loss + 5*landmarks_loss + 5*pose_loss
            
            #print("type total loss: ", total_loss.grad_fn)
            #optimizer = torch.optim.Adam(hf.parameters(), lr=args.learn_rate)

            optimizer.zero_grad()
            #print("before:", hf.fc_detection1[0].weight.grad)
            #total_loss.register_hook(lambda grad: print(grad))
            total_loss.backward()                                                   # Look into layers and set accoridingly set_grad = False
            #print("after:", hf.fc_detection2[0].bias.grad.sum())
            #print("total_loss.grad:",total_loss.grad)
            #print(total_loss.is_leaf)
            #print("AFTER")
            #if epoch==0:
            #    for name,param in hf.named_parameters():
            #        print(name)
            #        print(param)
            #        print(param.grad)
            #pdb.set_trace()
            optimizer.step()
            face_losses.append(face_loss.data.item())
            landmark_losses.append(landmarks_loss.data.item())
            pose_losses.append(pose_loss.data.item())
            losses.append(total_loss.data.item())
            

        #avg_loss = np.mean(losses)
        #train_cross_losses.append(avg_face_loss)
        time_elapsed = time.time() - start
        #print(total_loss.grad_fn)
        #print(total_loss.grad_fn.next_functions[0][0])
        #print(total_loss.grad_fn.next_functions[0][0].next_functions[0][0])
        #print(total_loss.grad_fn.next_functions[0][0].next_functions[0][0].next_functions[0][0])
        #print(total_loss.grad_fn.next_functions[0][0].next_functions[0][0].next_functions[0][0].next_functions[0][0])
        
        
        
       #print('Epoch [%d/%d], Train Face Loss: %.4f, Time (s): %d' % (
       #    epoch+1, args.epochs, np.mean(face_losses), time_elapsed))
       #print('Epoch [%d/%d], Train Landmark Loss: %.4f, Time (s): %d' % (
       #    epoch+1, args.epochs, np.mean(landmark_losses), time_elapsed))
       #print('Epoch [%d/%d], Train Pose Loss: %.4f, Time (s): %d' % (
       #    epoch+1, args.epochs, np.mean(pose_losses), time_elapsed))
       #
        print('Epoch [%d/%d], Train Loss: %.4f, Time (s): %d' % (
            epoch+1, args.epochs, np.mean(losses), time_elapsed))
        
        
        file.write("\r\n")
        file.write("%f ," % np.mean(face_losses))
        file.write("%f ," % np.mean(landmark_losses))
        file.write("%f ," % np.mean(pose_losses))
        file.write("%f ," % np.mean(losses))
        
        hf.eval()

        cross_val_loss = run_validation_step(hf, x_val, y_val_face, y_val_landmarks, y_val_pose, args.batch_size) 


        time_elapsed = time.time() - start
        #valid_cross_losses.append(cross_val_loss)    

        print('Epoch [%d/%d],  Val Loss: %.4f,  Time(s): %d' % (
            epoch+1, args.epochs, cross_val_loss, time_elapsed))
    
    checkpoint = {#'model': hyperface(),
          'state_dict': hf.state_dict(),
          'optimizer' : optimizer.state_dict()}

    if args.save_path:
        print('Saving model...')
        torch.save(checkpoint, args.save_path)
        print('model saved!')
        
    return hf

class AttrDict(dict):
    def __init__(self, *args, **kwargs):
        super(AttrDict, self).__init__(*args, **kwargs)
        self.__dict__ = self

args = AttrDict()
args_dict = {
              'gpu':True, 
              'valid':False, 
              'data': '', # give the path for data
              'model':"hyperface",
              'load_path' :"model_7.pth", #path to laod model
              'learn_rate': 0.00001,
              'batch_size':64, 
              'epochs':5, 
              'seed':0,
              'plot':True, 
              'experiment_name': 'hyperface',
              'save_path':"model_7.pth", #path to save model
              'visualize': False,
              'downsize_input':False,
}

train_list = [
                'helen836.npy','helen1029.npy','helen1233.npy','helen1439.npy',
                'helen208.npy','helen209.npy','helen416.npy','helen421.npy','helen615.npy',
                'helen620.npy','test.npy','helen192.npy',
             ]
a1 =  np.load('helen836.npy', allow_pickle=True)
a2 =  np.load('helen1029.npy', allow_pickle=True)
a3 =  np.load('helen1233.npy', allow_pickle=True)
a4 =  np.load('helen1439.npy', allow_pickle=True)
a5 =  np.load('helen208.npy', allow_pickle=True)
a6 =  np.load('helen209.npy', allow_pickle=True)
a7 =  np.load('helen416.npy', allow_pickle=True)
a8 =  np.load('helen421.npy', allow_pickle=True)
a9 =  np.load('helen615.npy', allow_pickle=True)
a10 = np.load('helen620.npy', allow_pickle=True)
a12 = np.load('test.npy', allow_pickle=True)

outer_epochs = 25

for j in range(outer_epochs):
    print("Outer Epoch: ", j)
    for i in a1,a2,a3,a4,a5,a6,a7,a8,a9,a10,a12:
        args_dict['data'] = i
        args.update(args_dict)
        fp = train(args)
        torch.cuda.empty_cache()
    #print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')
    #print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')
    print("#####################################################################")

file.close()

